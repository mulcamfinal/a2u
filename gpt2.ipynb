{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"gpt2.ipynb","provenance":[],"authorship_tag":"ABX9TyMKM2x6uz3sv3A7aGJiptqu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"LAju5zRIPLaA"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OXkJrKfJUwqA"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iujYObL_ZH_B"},"source":["!pip install -r /content/drive/MyDrive/gh/a2u/requirements.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kNThywfXaxgA"},"source":["import random\n","import torch\n","from torch.utils.data import DataLoader # 데이터로더\n","from gluonnlp.data import SentencepieceTokenizer \n","from model.torch_gpt2 import GPT2Config, GPT2LMHeadModel # model폴더의 torch_gpt2.py의 \n","# from transformers.configuration_gpt2 import GPT2Config 를 from transformers import GPT2Config로 변경해 오류 잡음\n","from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast\n","from util.data import FairyDataset\n","import gluonnlp\n","from tqdm import tqdm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rlcoDNULbThb"},"source":["ctx= 'cuda'#'cuda' #'cpu' #학습 Device CPU or GPU. colab의 경우 GPU 사용\n","cachedir='/content/drive/MyDrive/textG/kogpt2/' # KoGPT-2 모델 다운로드 경로\n","save_path = '/content/drive/MyDrive/textG/checkpoint/'\n","use_cuda = True # Colab내 GPU 사용을 위한 값\n","\n","kogpt2_config = {\n","    \"initializer_range\": 0.02,\n","    \"layer_norm_epsilon\": 1e-05,\n","    \"n_ctx\": 1024,\n","    \"n_embd\": 768,\n","    \"n_head\": 12,\n","    \"n_layer\": 12,\n","    \"n_positions\": 1024,\n","    \"vocab_size\": 51200\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z-kcJdZIbWdH"},"source":["\n","# KoGPT-2 언어 모델 학습을 위한 GPT2LMHeadModel 선언\n","kogpt2model = GPT2LMHeadModel(config=GPT2Config.from_dict(kogpt2_config))\n","# model_path로부터 다운로드 받은 내용을 load_state_dict으로 업로드\n","kogpt2model.from_pretrained(\"skt/kogpt2-base-v2\")\n","\n","# 추가로 학습하기 위해 .train() 사용\n","kogpt2model.train()\n","vocab_b_obj = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\", bos_token='<s>', eos_token='</s>', unk_token='<unk>',  pad_token='<pad>', mask_token='<mask>')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FOUGrVQsbXLv"},"source":["model, vocab = kogpt2model, vocab_b_obj.get_vocab()\n","sentencepieceTokenizer = vocab_b_obj.tokenize\n","#os.chdir(\"../\")\n","# data_file_path = '/content/drive/MyDrive/Colab Notebooks/narrativeKoGPT2/data/backmyo_novel_1/dataset_0825.txt'\n","data_file_path = '/content/drive/MyDrive/Colab Notebooks/create_data/use_data/구텐베르크 동화/total_data.txt'\n","# /content/drive/MyDrive/Colab Notebooks/create_data/use_data/dataset_2.txt 이솝우화 약 312개\n","dataset = FairyDataset(data_file_path, vocab, sentencepieceTokenizer)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jNxukdGLbamo"},"source":["batch_size = 4 # batch_size 1이면 오류안남 2면 오류남/ 고침\n","fairy_data_loader = DataLoader(dataset, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kZ8jxFRPbeAA"},"source":["# 1e-4 5e-5 2.5e-5 2e-5\n","learning_rate = 1e-4 # 학습률 잠시 수정 원래는 1e-5임\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"roWHeroebgNc"},"source":["# 메모리 오류 나면 사용\n","import torch, gc\n","gc.collect()\n","torch.cuda.empty_cache()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fyOOLtDJbh5o"},"source":["\n","model.cuda()\n","print('KoGPT-2 Transfer Learning Start')\n","epochs=200\n","# 학습률에 따른 에폭 조정해서 돌아가도록 코드 수정해야함\n","for epoch in range(epochs):\n","    count = 0\n","    print(epoch)\n","    for data in fairy_data_loader:\n","        optimizer.zero_grad()\n","        data = torch.stack(data) # list of Tensor로 구성되어 있기 때문에 list를 stack을 통해 변환해준다.\n","        data= data.transpose(1,0)\n","        \n","        data= data.to(ctx)\n","   \n","        outputs = model(data, labels=data)\n","        loss, logits = outputs[:2]\n","        loss.backward()\n","        optimizer.step()\n","        if count %10 ==0:\n","            print('epoch no.{} train no.{}  loss = {}' . format(epoch, count+1, loss))\n","            # torch.save(model,save_path+'checkpoint_{}_{}.tar'.format(epoch,count))\n","            # 추론 및 학습 재개를 위한 일반 체크포인트 저장하기\n","\n","        count += 1\n","\n","print(\"save!\")\n","save_path = '/content/drive/MyDrive/Colab Notebooks/narrativeKoGPT2/checkpoint/'       \n","torch.save({\n","        'epoch': epoch,\n","        'train_no': count,\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","        'loss':loss\n","    }, save_path+'gt_checkpoint_2.tar')"],"execution_count":null,"outputs":[]}]}